

[
  
  
    
    
      {
        "title": "Hello World",
        "excerpt": "This is my very first blog post. I haven’t written anything yet but I’m sure I have some great stories to tell.\n",
        "content": "This is my very first blog post. I haven’t written anything yet but I’m sure I have some great stories to tell.\n",
        "url": "/general/2018/08/22/hello-world/"
      },
    
      {
        "title": "Solving a Kaggle ML classification problem using XGBoost",
        "excerpt": "Introduction\n",
        "content": "Introduction\n\nThis post is about my first ever participation in a kaggle competition. The competition was organized by the Machine Learning techers of the MSc course I’m currently doing. To be honest, I had no idea about how to get through this kind of competition, but since it was a mandatory assignment and I had to do it, I really spent a lot of time trying to get the best possible score. All the details about the classification problem can be found in\nkaggle, and the whole implementation of the model can be found in this public repo.\n\n\n  Disclaimer:\nThis post is not intended to show a rigurous and very formal approach of the problem solving, actually is intended to do the complete opposite. I will try to show how me and my colleague tackled the problem when knowing almost nothing in machine learning and how we obtained a score higher than 99%. For a more formal-ish approach of the work you can take a look at the report we wrote.\n\n\nSummary\n\nBelow, there is a summary of the whole pipeline. On the next blocks, we\nwill dive deeply in all the modules shown.\n\n\n  \n  Figure 1: Summary pipeline breakdown\n\n\nPre-Processing\n\nThe Dataset\n\nThe dataset has been obtained from a real LTE deployment. During two\nweeks, different metrics were gathered from a set of 10 base stations,\neach having a different number of cells, every 15 minutes. The dataset\nis provided in the form of a csv file, where each row corresponds to a\nsample obtained from one particular cell at a certain time. Each data\nexample contains the following features:\n\n\n  \n    Time : hour of the day (in the format hh:mm) when the sample was\ngenerated.\n  \n  \n    CellName: text string used to uniquely identify the cell that\ngenerated the current sample. CellName is in the form xαLTE, where x\nidentifies the base station, and α the cell within that base station\n(see the example in the right figure).\n  \n  \n    PRBUsageUL and PRBUsageDL: level of resource utilization in that\ncell measured as the portion of Physical Radio Blocks (PRB) that\nwere in use (%) in the previous 15 minutes. Uplink (UL) and downlink\n(DL) are measured separately.\n  \n  \n    meanThrDL and meanThrUL: average carried traffic (in Mbps)\nduring the past 15 minutes. Uplink (UL) and downlink (DL) are\nmeasured separately.\n  \n  \n    maxThrDL and maxThrUL: maximum carried traffic (in Mbps)\nmeasured in the last 15 minutes. Uplink (UL) and downlink (DL) are\nmeasured separately.\n  \n  \n    meanUEDL and meanUEUL: average number of user equipment (UE)\ndevices that were simultaneously active during the last 15 minutes.\nUplink (UL) and downlink (DL) are measured separately.\n  \n  \n    maxUEDL and maxUEUL: maximum number of user equipment (UE)\ndevices that were simultaneously active during the last 15 minutes.\nUplink (UL) and downlink (DL) are measured separately.\nmaxUE_UL+DL: maximum number of user equipment (UE) devices that\nwere active simultaneously in the last 15 minutes, regardless of UL\nand DL.\n  \n  \n    Unusual: labels for supervised learning. A value of 0 determines\nthat the sample corresponds to normal operation, a value of 1\nidentifies unusual behavior.\n  \n\n\n# Clone repository in order to get access locally to the datasets\n!rm -rf .git README.md\n!git clone https://github.com/sergio-gimenez/anomaly-4G-detection \n\n\ntrain = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_train.csv', sep=';')\ntest = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_test.xls', sep=';' )\n\n# Separate labels from data \nX = train.drop('Unusual', axis='columns')\ny = train['Unusual']\n\n# We split the data into training and validation subsets (80% and 20%) in\n# order to validate our training\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, \n                                                                train_size=0.8,\n                                                                random_state=1, stratify = y)\nX_test = test\n\n\nUsing non-quantitative features\n\nFirst thing to do regarding data pre-processing is to make sure all\nfeatures are ready to be used, specially the non numerical ones: Time\nand CellName. Time has relevant correlation with the maximum traffic\nhours, although the day is not included in the date, still is a relevant\nenough feature. In order to make Time ready to use, there are several\napproaches. However, the chosen one has been to convert the time\n(minutes) to radians and split them up into two features, one applying a\ncosine and the other with sine. Regarding CellName, a simple mapping\n1:1 with a numerical identifier for each cell name has been carried out.\n\n#Refactor time feature to minuts and cellName to unique identifier 1:1\ndef getTimeInMinutes(x):\n  hh, mm  = x.split(\":\")\n  return int(hh)* 60 + int(mm)\n\ndef createCellNameDictionary(data):\n  cellList = []\n  for i in data[\"CellName\"]:\n    cellList.append(i)\n  cellList = set(cellList)\n  cellDict = {}\n  for idx, value in enumerate(cellList):\n    cellDict[value]=idx\n  return cellDict\n\ndef refactorFeaturesDataframe(data):\n  #data[\"Time\"] = data[\"Time\"].apply(lambda x: getTimeInMinutes(x))\n  data[\"TimeCos\"] = data[\"Time\"].apply(lambda x: math.cos(getTimeInMinutes(x)*math.pi/(12*60)))\n  data[\"TimeSin\"] = data[\"Time\"].apply(lambda x: math.sin(getTimeInMinutes(x)*math.pi/(12*60)))\n  del data[\"Time\"]\n\n  cellNameDict = createCellNameDictionary(data);\n  data[\"CellName\"] = data[\"CellName\"].apply(lambda x: cellNameDict[x])\n  return data\n\n\n#Refactoring data from features to useful values\nX_train_df = refactorFeaturesDataframe(X_train)\nX_train = X_train_df.to_numpy()\ny_train = y_train.to_numpy()\nX_validation = refactorFeaturesDataframe(X_validation).to_numpy()\ny_validation = y_validation.to_numpy()\nX_test = refactorFeaturesDataframe(test).to_numpy()\n\n\nData Visualisation\n\nPCA\n\nRegarding PCA, given the number of new features desired, it tries to\nprovide the projection using the correlation between some dimensions and\nkeeping the maximum amount of information about the original data\ndistribution. As can be seen in the image below, there are not clear\nclusters nor a clear defined pattern. Usual and unusual samples are\nmixed in many ways, fact that constraints the classifier that is going\nto be used, e.g linear classifiers can be directly excluded.\n\npca = PCA(n_components=3)  # Reduce to k=3 dimensions\nscaler = StandardScaler()\nX_norm = scaler.fit_transform(X_train)\nX_reduce = pca.fit_transform(X_norm)\n\ncolors=['green' if l==0 else 'red' for l in y_train]\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X_reduce[:,0], X_reduce[:, 1], X_reduce[:, 2], s=4, alpha=1,color=colors)\nplt.show()\n\n\n\n  \n  Figure 2: Normalized PCA reduction to 3 features of the whole dataset\n\n\nt-SNE\n\nIn order to go through a different approach, a non-linear reduction such\nas t-SNE has been tried out. t-SNE is an unsupervised method that\nminimizes the divergence between a distribution that measures pairwise\nsimilarities of the input and a distribution that measures the\nsimilarities of the corresponding low-dimensional points in the\nembedding. As it can be observed in the figure below, t-SNE has built a\nset of separable clusters but with samples of different classes mixed in\nthe same clusters, without a clear visual pattern.\n\nfrom sklearn.manifold import TSNE\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\ntsne_results = tsne.fit_transform(X_train)\n\ndf_subset={}\ndf_subset['tsne-2d-one'] = tsne_results[:,0]\ndf_subset['tsne-2d-two'] = tsne_results[:,1]\ndf_subset['Labels'] = y_train\n\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n    hue=\"Labels\",\n    palette=sns.color_palette(\"hls\", 2),\n    data=df_subset,\n    legend=\"full\",\n    alpha=0.3\n)\n\n\n\n  \n  Figure 3: Normalized t-SNE reduction in 2 dimension of the whole dataset\n\n\nPlain Vanilla Classifiers\n\nDue to the dataset nature, a linear classifier will not achieve an\nacceptable performance. A neural network did not work either due to the\nsmall dataset. A SVM with a Gaussian kernel was tested as well but, the\nresults were not as good as the ones obtained by decision tree. Some\nresults applying plain vanilla classifiers without any parameter tuning\nare shown in the table below. As it can be seen, the best performance is\nobtained with a plain vanilla decision tree. Therefore, we decided to\ndive deeply into that approach.\n\n\n  \n    \n      Classifier\n      Train Err.\n      Valdiation Err.\n      Accuracy\n    \n  \n  \n    \n      Decision Tree\n      0\n      0.03\n      0.96\n    \n    \n      SVM (rbf)\n      0.26\n      0.26\n      0.73\n    \n    \n      MLP\n      0.27\n      0.27\n      0.73\n    \n  \n\n\nSolving the Classification Problem\n\nXGBoost. Training the classifier\n\nOne of the widely ensembled methods are gradient boosted decision trees.\nIn a summarized way, boosting takes an iterative approach for training\nmodels. It trains models in succession, with each new model being\ntrained to correct the errors made by the previous ones. A widely used\nimplementation of the training described before is XGBoost. XGBoost\nis an optimized distributed gradient boosting library designed to be\nhighly efficient, flexible and portable.\nAll the necessary information about XGBoost can be found in the\nXGBoost Documentation Page\n\n\n\nNote:\n\nIf you want to avoid the training process, and use the pre trained\nmodel, make sure the xgb_model.joblib is loaded in\nanomaly-4G-detection/xgb_model.joblib.\n\nIf you want to go through the training process there are two ways:\n\n\n  \n    Fast way: The most suitable parameters we have found are already\nhardcoded in the pipe and no training process is involved at all in\nthis part.\n  \n  \n    Whole training process: If you want to do the whole training process\nby yourself comment the parameters in the pipe, comment\n\n    clf_GS = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=[(slice(None), slice(None))], n_iter= 1)\n    \n\n    and uncomment\n\n    clf_GS = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=5, n_iter= 500)  \n    \n  \n\n\nfrom xgboost import XGBClassifier, plot_importance\nfrom joblib import dump, load\nfrom google.colab import files\nfrom scipy.stats import uniform, randint\n\ntry:\n  clf_GS = load('anomaly-4G-detection/xgb_model.joblib') \n  training = False\n  \nexcept:\n  training = True\n  pipe = Pipeline(steps=[('std_slc', StandardScaler()),\n                         ('xgb_clf', XGBClassifier(random_state=1,\n                                                      scale_pos_weight=7,\n                                                      colsample_bytree= 0.053381469489678104,\n                                                      eta= 0.20289460663803338,\n                                                      gamma= 0.88723107873764,\n                                                      learning_rate= 0.15455380920536027,\n                                                      max_depth= 26,\n                                                      min_child_weight= 1,\n                                                      n_estimators= 565,\n                                                      subsample= 0.9738168894035317))])\n  \n  parameters = {\n  # 'xgb_clf__eta'    : uniform(0.2, 0.35),\n  # \"xgb_clf__colsample_bytree\": uniform(0.05, 0.2),\n  # \"xgb_clf__min_child_weight\": randint(1, 5),\n  # \"xgb_clf__gamma\": uniform(0.35, 0.6),\n  # \"xgb_clf__learning_rate\": uniform(0.1, 0.3), # default 0.1 \n  # \"xgb_clf__max_depth\": randint(10, 30), # default 3\n  # \"xgb_clf__n_estimators\": randint(500, 1000), # default 100\n  # \"xgb_clf__subsample\": uniform(0.6, 0.99)\n  }\n\n  #clf_GS = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=5, n_iter= 500)  \n  clf_GS = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=[(slice(None), slice(None))], n_iter= 1)\n  clf_GS.fit(X_train, y_train)    \n\n\nSelect features from model\n\nThe last experiment that leads to a considerable enhancement is to take\nadvantage of the features selected by the model to perform a feature\nreduction. Take into account that XGBoost, in essence, is a set of\nensemble decision trees, so we could evaluate its features importance\nonce the model is trained.\n\nEvaluating that data, we get the optimized threshold to reduce the\naccuracy using just 3 features (check next code block). The\n‘SelectFromModel’ module allowed us to pass the thresholds to the\nalready trained model and, once the best threshold is validated,\ntransform the datasets using just the features that pass the threshold.\nThis final experiment let us reduce the recall from 44 errors in\nvalidation to 14. In the test set we achieved a score of 99.83%, which\nwas our best performance in the challenge.\n\nfrom sklearn.feature_selection import SelectFromModel\n\nif training:\n\n  treshold_train_error = []\n  treshold_val_error = []\n  thresholds = np.sort(clf_GS.best_estimator_.named_steps[\"xgb_clf\"].feature_importances_)\n  \n  current_error = 100.0\n  best_th = 0\n\n  for thresh in thresholds:\n\n    # Do a feature reduction with relevant feature\n    new_X_train = X_train\n    selection = SelectFromModel(clf_GS.best_estimator_.named_steps[\"xgb_clf\"], threshold=thresh, prefit=True)\n    select_X_train = selection.transform(new_X_train)\n      \n    # Fit the classifier with the reduced dataset\n    selection_model = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=[(slice(None), slice(None))], n_iter= 1)\n    selection_model.fit(select_X_train, y_train)\n    \n    # Evaluate predictions with the dataset trained with the feature reduction\n    pred_train = selection_model.predict(select_X_train)\n    select_X_val = selection.transform(X_validation)\n    pred_val = selection_model.predict(select_X_val)\n    \n\n    \"\"\"\"                       \n         Classification report\n         ---------------------\n    \"\"\"\n    train_error = 1. - accuracy_score(y_train, pred_train)    \n    train_cmat = confusion_matrix(y_train, pred_train)\n    val_error = 1. - accuracy_score(y_validation, pred_val)\n    val_cmat = confusion_matrix(y_validation, pred_val)\n\n    treshold_train_error.append(train_error)\n    treshold_val_error.append(val_error)\n\n    print(\"\\nThreshold of value %f\" % thresh)\n    print(\"--------------------------------\")\n    print('\\ntrain error: %f ' % train_error)\n    print('train confusion matrix:')\n    print(train_cmat)\n    print('\\ntest error: %f ' % val_error)\n    print('test confusion matrix:')\n    print(val_cmat)\n    print(\"\\n\")\n\n    if val_error &lt; current_error:\n      current_error = val_error\n      best_th = thresh\n      best_transformation = select_X_train\n\n\nTrain and predict the data with the best feature reduction\n\n  from sklearn.feature_selection import SelectFromModel\n\n  # Get the best estimator we found in the previous block\n  new_X_train = X_train\n  selection = SelectFromModel(clf_GS.best_estimator_.named_steps[\"xgb_clf\"], threshold=best_th , prefit=True)\n  select_X_train = selection.transform(new_X_train)\n\n  # Train the classifier with the best feature reduction\n  selection_model = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=[(slice(None), slice(None))], n_iter= 1)\n  selection_model.fit(select_X_train, y_train)\n\n  # Save the model in a file and download locally.\n  dump(clf_GS, 'xgb_model.joblib')\n  files.download('xgb_model.joblib')\n\n  pred_train = selection_model.predict(select_X_train)\n  select_X_val = selection.transform(X_validation)\n  pred_val = selection_model.predict(select_X_val)\n\n  train_error = 1. - accuracy_score(y_train, pred_train)\n  train_cmat = confusion_matrix(y_train, pred_train)\n  val_error = 1. - accuracy_score(y_validation, pred_val)\n  val_cmat = confusion_matrix(y_validation, pred_val)\n\n  \n  \"\"\"\"                       \n         Classification report\n         ---------------------\n  \"\"\"\n\n  print(\"\\nThreshold of value %f\" % thresh)\n  print(\"--------------------------------\")\n  print('\\ntrain error: %f ' % train_error)\n  print('train confusion matrix:')\n  print(train_cmat)\n  print('\\ntest error: %f ' % val_error)\n  print('test confusion matrix:')\n  print(val_cmat)\n  print(\"\\n\")\n\n  print(\"TRAINING\\n\" + classification_report(y_train, pred_train))\n  print(\"\\nTESTING\\n\" + classification_report(y_validation, pred_val))\n\n\nAnd the results of the best estimator:\n\n\nThreshold of value 0.462643\n--------------------------------\n\ntrain error: 0.000034 \ntrain confusion matrix:\n[[21376     1]\n [    0  8146]]\n\ntest error: 0.002439 \ntest confusion matrix:\n[[5340    4]\n [  14 2023]]\n\n\nTRAINING\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     21377\n           1       1.00      1.00      1.00      8146\n\n    accuracy                           1.00     29523\n   macro avg       1.00      1.00      1.00     29523\nweighted avg       1.00      1.00      1.00     29523\n\n\nTESTING\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      5344\n           1       1.00      0.99      1.00      2037\n\n    accuracy                           1.00      7381\n   macro avg       1.00      1.00      1.00      7381\nweighted avg       1.00      1.00      1.00      7381\n\n\n\nInsightful data visualization\n\nHere, there is some data visualisation in order to see and understand why and what improved by performing the feature reduction.\n\nEvolution of the error for different thresholds\n\nThis plot shows the improvement we gained by implementing the ‘Feature Selection’ module.\n\n  fig, ax = plt.subplots()\n  ax.plot(thresholds, treshold_train_error, label='training')\n  ax.plot(thresholds, treshold_val_error, label='validation')\n  ax.set(xlabel='Threshold', ylabel='Error')\n  ax.legend()\n  plt.title('Evolution of the error for different thresholds')\n  plt.show()\n\n\n  \n  Figure 4: Loss vs threshold selection on feature reduction\n\n\nBest performance feature reduction\n\nOur best feature reduction has 3 features , so then we can plot the resulting data set.\n\n  colors=['green' if l==0 else 'red' for l in y_train]\n  fig = plt.figure()\n  ax = fig.add_subplot(111, projection='3d')\n  ax.scatter(best_transformation[:,0], best_transformation[:, 1], best_transformation[:, 2], s=4, alpha=1,color=colors)\n\n  plt.title('Best-Performance Feature Reduction')\n  plt.show()\n\n\n\n  \n  Figure 5: Best Feature Reduction\n\n\nFeature importance\n\nIn this plot, is shown the features that are more relevant to XGBoost when it comes to classify.\n\n  feature_importances = clf_GS.best_estimator_.named_steps[\"xgb_clf\"].feature_importances_\n  columns = X_train_df.columns\n  \n  fig = plt.figure() \n  plt.bar(np.arange(14) , feature_importances, align='center', alpha=0.5)\n  plt.xticks(np.arange(14), columns, rotation='vertical')\n  plt.ylabel('Normalized Importance')\n  plt.title('Feature Importance')\n  plt.show()\n\n\n\n  \n  Figure 6: Feature importances by the XGBoost\n\n\n\nConclusions\n\nDuring this research, we have explored a vast amount of possible classifiers and techniques to deal with the binary classification problem exposed in this report. Among those all classifiers, XGBoost has resulted to be the proper one to perform this task, as other related resources suggested.\n\nFar from the scope of this work, on a real production environment, this system is combined with lagged variables and treat as a time series challenge, as mentioned on. However, the work conducted in this post serves as a proof of concept showing how powerful XGBoost is when comes to tackle problems of similar nature.\n",
        "url": "/tech/2021/01/23/kaggle_md/"
      },
    
  
  
  
  {
    "title": "About me",
    "excerpt": "\n",
    "content": "I’ll fill this part at some point. You can find me in linkedin in the meanwhile.\n",
    "url": "/about/"
  },
  
  {
    "title": "Categories",
    "excerpt": "Category index\n",
    "content": "\n",
    "url": "/categories/"
  },
  
  {
    "title": "Blog",
    "excerpt": "\n",
    "content": "\n",
    "url": "/blog/"
  },
  
  {
    "title": "Welcome to my website",
    "excerpt": "\n",
    "content": "There isn’t much going on here yet, but watch this space\n\nWriting a blog is one of the things I have had always in mind. People usually well, actually only my mother does tell me that I have good writing abilities. Since people my mother says I’m not bad at all at it and I feel good about writing stuff in the internet I will give it a try. (Even probably no one will care about)\n",
    "url": "/"
  }
  
]

